{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:8]\n",
    "Y = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pima-indians-diabetes.csv')\n",
    "X = data.iloc[:,:8]\n",
    "Y = data.iloc[:,8]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "discretisation_mode = 'LOG'\n",
    "bins_count = 5\n",
    "scoring = {'acc': 'accuracy', 'prec_macro': 'precision_macro', 'rec_micro': 'recall_macro', 'f1': 'f1_macro'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00102735, 0.00150394, 0.00102735, 0.00100398, 0.00050354]),\n",
       " 'score_time': array([0.00147939, 0.00150394, 0.00150228, 0.00097847, 0.00150084]),\n",
       " 'test_acc': array([0.62337662, 0.67532468, 0.63636364, 0.61437908, 0.65359477]),\n",
       " 'test_f1': array([0.57899698, 0.54684557, 0.49246704, 0.53861487, 0.53194805]),\n",
       " 'test_prec_macro': array([0.58096154, 0.64746732, 0.55310458, 0.54965675, 0.58969466]),\n",
       " 'test_rec_micro': array([0.57796296, 0.56685185, 0.52407407, 0.5409434 , 0.54877358]),\n",
       " 'train_acc': array([0.64820847, 0.65960912, 0.66612378, 0.65365854, 0.66666667]),\n",
       " 'train_f1': array([0.58223398, 0.54810174, 0.55864047, 0.59385048, 0.56258132]),\n",
       " 'train_prec_macro': array([0.59723155, 0.60516175, 0.61748988, 0.60670732, 0.61966019]),\n",
       " 'train_rec_micro': array([0.58115654, 0.56057243, 0.56883178, 0.59177326, 0.57165698])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discretizate(mode, column, bin_count):\n",
    "    if mode == 'CUT':\n",
    "        return pd.cut(column, bin_count, labels=False)\n",
    "    elif mode == 'QCUT':\n",
    "        return pd.qcut(column, bin_count, labels=False, duplicates='drop')\n",
    "    elif mode == 'LOG':\n",
    "        return np.digitize(column, np.geomspace(1, np.max(column), num=10))\n",
    "    else:\n",
    "        return column\n",
    "\n",
    "# discretization\n",
    "for column in X:\n",
    "    bins = discretizate(discretisation_mode, X[column], bins_count)\n",
    "    X[column] = bins\n",
    "    data[column] = bins\n",
    "    \n",
    "model = MultinomialNB(alpha=1.0)\n",
    "\n",
    "cross_validate(model, X, Y, scoring=scoring, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
